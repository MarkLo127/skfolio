{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Custom Pre-selection Using Volumes\n\nThis tutorial demonstrates how to implement a custom `pre-selection transformer\n<pre_selection>` with `metadata-routing <metadata_routing>`, integrate it into\na `Pipeline`, and run walk-forward cross-validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\nWe will use the S&P 500 `dataset <datasets>`, which contains daily prices\nof 20 assets from the S&P 500 Index, spanning from 1990-01-02 to 2022-12-28:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport sklearn.base as skb\nimport sklearn.feature_selection as skf\nimport sklearn.utils.validation as skv\nfrom plotly.io import show\nfrom sklearn import set_config\nfrom sklearn.pipeline import Pipeline\n\nfrom skfolio.datasets import load_sp500_dataset\nfrom skfolio.model_selection import (\n    WalkForward,\n    cross_val_predict,\n)\nfrom skfolio.optimization import EqualWeighted\nfrom skfolio.preprocessing import prices_to_returns\n\nprices = load_sp500_dataset()\nX = prices_to_returns(prices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For simplicity, we will generate random volume data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "volumes_usd = np.random.rand(*X.shape) * 1e6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Pre-selection Transformer\nLet's create a custom pre-selection transformer to retain the top x% of assets\nwith the highest average volumes during the fitting period.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class VolumePreSelection(skf.SelectorMixin, skb.BaseEstimator):\n    to_keep_: np.ndarray\n\n    def __init__(self, pct_to_keep: float = 0.5):\n        self.pct_to_keep = pct_to_keep\n\n    def fit(self, X, y=None, volumes=None):\n        # Validate and convert X to a NumPy array\n        X = self._validate_data(X)\n\n        # Check parameters\n        if not 0 < self.pct_to_keep <= 1:\n            raise ValueError(\n                \"`pct_to_keep` must be between 0 and 1\"\n            )\n\n        # Validate and convert volumes to a NumPy array\n        volumes = skv.check_array(\n            volumes,\n            accept_sparse=False,\n            ensure_2d=False,\n            dtype=[np.float64, np.float32],\n            order=\"C\",\n            copy=False,\n            input_name=\"volumes\",\n        )\n        if volumes.shape != X.shape:\n            raise ValueError(\n                f\"Volume data {volumes.shape} must have the same dimensions as X {X.shape}\"\n            )\n\n        n_assets = X.shape[1]\n        mean_volumes = volumes.mean(axis=0)\n\n        # Select the top `pct_to_keep` assets with the highest average volumes\n        n_to_keep = max(1, int(round(self.pct_to_keep * n_assets)))\n        selected_idx = np.argsort(mean_volumes)[-n_to_keep:]\n\n        # Performance tip: `argpartition` could be used here for better efficiency\n        # (O(n log(n)) vs O(n)).\n        self.to_keep_ = np.isin(np.arange(n_assets), selected_idx)\n        return self\n\n    def _get_support_mask(self):\n        skv.check_is_fitted(self)\n        return self.to_keep_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline\nWe create a `Pipeline` that uses our custom pre-selection transformer to retain the\ntop 30% of assets based on average volume, followed by an equal-weighted allocation.\nSince we are using volume metadata, we enable metadata-routing and specify how\nto route it with `set_fit_request`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "set_config(enable_metadata_routing=True, transform_output=\"pandas\")\n\nmodel = Pipeline(\n    [\n        (\n            \"pre_selection\",\n            VolumePreSelection(pct_to_keep=0.3).set_fit_request(\n                volumes=True\n            ),\n        ),\n        (\"optimization\", EqualWeighted()),\n    ]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross-Validation\nWe will cross-validate the model using a Walk Forward that rebalances\nthe portfolio every 3 months on the 3rd Friday, training on the preceding 6 months:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv = WalkForward(test_size=3, train_size=6, freq=\"WOM-3FRI\")\n\npred = cross_val_predict(model, X, cv=cv, params={\"volumes\": volumes_usd})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the weights for each rebalancing period:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred.composition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also view the weights for each day:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred.weights_per_observation.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the weights per rebalancing period:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = pred.plot_composition()\nshow(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "|\n\nPlot the full out-of-sample walk-forward path:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred.plot_cumulative_returns()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}