{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Using Implied Volatility with Metadata Routing\n\nThis tutorial shows how to use `metadata routing <metadata_routing>`.\n\nWe will use the :class:`~skfolio.moments.ImpliedCovariance` estimator inside\noptimization models and grid search procedures to show how the implied volatility\ntime series can be routed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Datasets\nWe load the S&P 500 `dataset <datasets>` composed of the daily prices of 20\nassets from the S&P 500 Index composition and the implied volatility time series\nof these 20 assets starting from 2010-01-04 up to 2022-12-28.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport plotly.express as px\nfrom plotly.io import show\nfrom sklearn import set_config\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\nfrom skfolio import Population, RatioMeasure\nfrom skfolio.datasets import load_sp500_dataset, load_sp500_implied_vol_dataset\nfrom skfolio.metrics import make_scorer\nfrom skfolio.model_selection import WalkForward, cross_val_predict\nfrom skfolio.moments import (\n    EmpiricalCovariance,\n    GerberCovariance,\n    ImpliedCovariance,\n    LedoitWolf,\n)\nfrom skfolio.optimization import InverseVolatility, MeanRisk\nfrom skfolio.preprocessing import prices_to_returns\nfrom skfolio.prior import EmpiricalPrior\n\nprices = load_sp500_dataset()\nimplied_vol = load_sp500_implied_vol_dataset()\n\nX = prices_to_returns(prices)\nX = X.loc[\"2010\":]\n\nimplied_vol.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implied Covariance Estimator\nWe use the :class:`~skfolio.moments.ImpliedCovariance` estimator as an example for\nmetadata routing because, in addition to the assets' returns `X`, it also needs\nthe assets' implied volatilities passed to its `fit` method.\n\nBelow, we give a quick summary of the estimator. The detailed\ndocumentation and literature references are available in the docstring:\n:class:`~skfolio.moments.ImpliedCovariance`.\n\nFor each asset, the implied volatility time series is used to estimate the realised\nvolatility using the non-overlapping log-transformed OLS model:\n\n\\begin{align}\\ln(RV_{t}) = \\alpha + \\beta_{1} \\ln(IV_{t-1}) + \\beta_{2} \\ln(RV_{t-1}) + \\epsilon\\end{align}\n\nwith $\\alpha$, $\\beta_{1}$ and $\\beta_{2}$ the intercept and\ncoefficients to estimate, $RV$ the realised volatility, and $IV$ the\nimplied volatility. The training set uses non-overlapping data of sample size\n`window_size` to avoid possible regression errors caused by auto-correlation.\nThe logarithmic transformation of volatilities is used for its better finite sample\nproperties and distribution, which is closer to normality, less skewed and\nleptokurtic.\n\nThe final step is the reconstruction of the covariance matrix from the correlation\nand estimated realised volatilities $D$:\n\n\\begin{align}\\Sigma = D \\ Corr \\ D\\end{align}\n\nWith $Corr$, the correlation matrix computed from the prior covariance\nestimator. The default is the `EmpiricalCovariance`. It can be changed to any\ncovariance estimator using `prior_covariance_estimator`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = ImpliedCovariance()\nmodel.fit(X, implied_vol=implied_vol)\nprint(model.covariance_.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The intercept, coefficients and R2 score are saved in `model.intercepts_`,\n`model.coefs_` and `model.r2_scores_`\n\nLet's analyse the R2 score as a function of the window size:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coefs = {}\nfor window_size in [10, 20, 60, 100]:\n    model = ImpliedCovariance(window_size=window_size)\n    model.fit(X, implied_vol=implied_vol)\n    coefs[window_size] = model.r2_scores_\n\ndf = (\n    pd.DataFrame(coefs, index=X.columns)\n    .unstack()\n    .reset_index()\n    .rename(columns={\"level_0\": \"Window Size\", \"level_1\": \"Asset\", 0: \"R2 score\"})\n)\ndf[\"Window Size\"] = df[\"Window Size\"].astype(str)\nfig = px.bar(\n    df,\n    x=\"Asset\",\n    y=\"R2 score\",\n    color=\"Window Size\",\n    barmode=\"group\",\n    title=\"R2 score per Window Size\",\n)\nshow(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "|\n\nLet's print the average R2 per window size:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print({k: f\"{np.mean(v):0.1%}\" for k, v in coefs.items()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The highest R2 is achieved for a window size of 20 observations.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inverse Volatility\nTo use the `ImpliedCovariance` estimator inside a meta-estimator such as the\n`InverseVolatility`, you must enable metadata routing with `set_config` and\nspecify where to route the implied vol using `set_fit_request` as shown below:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "set_config(enable_metadata_routing=True)\n\nmodel = InverseVolatility(\n    prior_estimator=EmpiricalPrior(\n        covariance_estimator=ImpliedCovariance().set_fit_request(implied_vol=True)\n    )\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then you can pass the implied volatility to the `fit` method of the meta-estimator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.fit(X, implied_vol=implied_vol)\nprint(model.weights_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross Validation\nIn this section, we show how to use metadata routing with `cross_val_predict`.\nFirst, we create a `WalkForward` cross-validator to rebalance our portfolio every 20\nbusiness days by re-fitting the model on the previous 400 business days (~ 1.5 years):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv = WalkForward(train_size=400, test_size=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the model created above and pass the implied volatility in `params`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred_model = cross_val_predict(model, X, cv=cv, params={\"implied_vol\": implied_vol})\npred_model.name = \"Implied Vol\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compare the model with a benchmark using `InverseVolatility` with the default\n`EmpiricalCovariance` estimator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "benchmark = InverseVolatility()\npred_bench = cross_val_predict(benchmark, X, cv=cv)\npred_bench.name = \"Benchmark\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For easier analysis, we add both predicted portfolios into a `Population`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population = Population([pred_bench, pred_model])\nsummary = population.summary()\nprint(summary.loc[[\"Annualized Standard Deviation\", \"Annualized Sharpe Ratio\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the Composition and Cumulative returns:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population.plot_composition(display_sub_ptf_name=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population.plot_cumulative_returns()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyper-Parameters Tuning\nIn this section, we show how to use metadata routing with `GridSearchCV`.\nFirst, we split the data into a train and a test set:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train, X_test, implied_vol_train, implied_vol_test = train_test_split(\n    X, implied_vol, test_size=1 / 2, shuffle=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a Minimum Variance that uses the `ImpliedCovariance` estimator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = MeanRisk(\n    prior_estimator=EmpiricalPrior(\n        covariance_estimator=ImpliedCovariance().set_fit_request(implied_vol=True)\n    )\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we find the hyper-parameters of the `ImpliedCovariance` estimator that\nmaximizes the out-of-sample Sharpe Ratio of the Minimum Variance model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grid_search = GridSearchCV(\n    estimator=model,\n    param_grid={\n        \"prior_estimator__covariance_estimator__window_size\": np.arange(5, 50, 3),\n        \"prior_estimator__covariance_estimator__prior_covariance_estimator\": [\n            LedoitWolf(),\n            GerberCovariance(),\n            EmpiricalCovariance(),\n        ],\n    },\n    return_train_score=True,\n    scoring=make_scorer(RatioMeasure.ANNUALIZED_SHARPE_RATIO),\n    n_jobs=-1,\n    cv=cv,\n)\ngrid_search.fit(X_train, implied_vol=implied_vol_train)\ngs_model = grid_search.best_estimator_\nprint(gs_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the out-of-sample Sharpe Ratio as a function of the window size and\nthe prior covariance estimator used to compute the correlation matrix:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv_results = grid_search.cv_results_\n\ndf = pd.DataFrame(\n    {\n        \"Prior Cov Estimator\": [\n            str(x)\n            for x in cv_results[\n                \"param_prior_estimator__covariance_estimator__prior_covariance_estimator\"\n            ]\n        ],\n        \"Window Size\": cv_results[\n            \"param_prior_estimator__covariance_estimator__window_size\"\n        ],\n        \"Test Sharpe Ratio\": cv_results[\"mean_test_score\"],\n        \"error\": cv_results[\"std_test_score\"] / 10,  # one tenth of std for readability\n    }\n)\npx.line(\n    df,\n    x=\"Window Size\",\n    y=\"Test Sharpe Ratio\",\n    color=\"Prior Cov Estimator\",\n    error_y=\"error\",\n    title=\"Out-of-Sample Sharpe Ratio\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we compare the optimal Grid Search model with a naive Minimum Variance\nbenchmark on the **test set**:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred_gs_model = cross_val_predict(\n    gs_model, X_test, params={\"implied_vol\": implied_vol_test}, cv=cv, n_jobs=-1\n)\npred_gs_model.name = \"GS Model\"\n\nbenchmark = MeanRisk()\npred_bench = cross_val_predict(benchmark, X_test, cv=cv)\npred_bench.name = \"Benchmark\"\n\npopulation = Population([pred_bench, pred_gs_model])\nsummary = population.summary()\nprint(summary.loc[[\"Annualized Standard Deviation\", \"Annualized Sharpe Ratio\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population.plot_cumulative_returns()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\nThis was a toy example to introduce the metadata routing API.\nFor more information, see `Metadata Routing User Guide <metadata_routing>`.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}